name: Collect & Parse Artifacts (fan-in)

# Will be triggered by the completion of any of the following workflows:
on:
  workflow_run:
    workflows: ["Rust Benchmarks (parallel)", "Non-Rust Benchmarks (parallel)"]
    types: [completed]

# collapse multiple triggers for the same commit into one survivor
concurrency:
  group: fanin-${{ github.event.workflow_run.head_sha }}
  cancel-in-progress: true

permissions:
  actions: read
  contents: read

jobs:
  collect:
    runs-on: macos-latest
    env:
      SHA: ${{ github.event.workflow_run.head_sha }}
      # keep in sync with on.workflow_run.workflows
      REQUIRED_WORKFLOWS_JSON: '["Rust Benchmarks (parallel)", "Non-Rust Benchmarks (parallel)"]'
      WAIT_SECONDS: "30"
      MAX_TRIES: "80" # 30 Ã— 80 = ~40 min max wait
    steps:
      - uses: actions/checkout@v4

      # Installation is necessary for a non-GitHub runner
      - name: Install gh
        run: brew install gh

      - name: Install jq
        run: brew install jq

      - name: Auth gh
        run: gh auth setup-git
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Wait until all parent workflows are completed for this commit
        id: wait
        shell: bash
        run: |
          set -euo pipefail
          echo "Target SHA: $SHA"
          tries=0
          while (( tries < MAX_TRIES )); do
            all_done=true
            any_failed=false
            summary=""
            # build array of workflow names from JSON env
            mapfile -t WORKFLOWS < <(jq -r '.[]' <<<"$REQUIRED_WORKFLOWS_JSON")
            for wf in "${WORKFLOWS[@]}"; do
              # List recent runs for this workflow, pick the one matching head SHA
              run_json=$(gh run list --workflow "$wf" --limit 50 \
                --json databaseId,headSha,conclusion,status,displayTitle,workflowName \
                --jq "map(select(.headSha==\"$SHA\"))[0]")
              if [[ "$run_json" == "null" || -z "$run_json" ]]; then
                all_done=false
                summary+="$wf: pending (not started)\n"
                continue
              fi
              status=$(jq -r '.status' <<<"$run_json")
              conclusion=$(jq -r '.conclusion' <<<"$run_json")
              run_id=$(jq -r '.databaseId' <<<"$run_json")
              summary+="$wf: status=$status conclusion=$conclusion run_id=$run_id\n"
              if [[ "$status" != "completed" ]]; then
                all_done=false
              elif [[ "$conclusion" != "success" ]]; then
                any_failed=true
              fi
            done
            echo -e "$summary"
            if $all_done; then
              if $any_failed; then
                echo "One or more parents failed. Proceeding to collect what is available."
              else
                echo "All parents completed successfully."
              fi
              break
            fi
            tries=$((tries+1))
            sleep "$WAIT_SECONDS"
          done
          if (( tries >= MAX_TRIES )); then
            echo "Timeout waiting for parent workflows." >&2
            exit 1
          fi

      - name: Download artifacts from each parent run
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p inbox
          mapfile -t WORKFLOWS < <(jq -r '.[]' <<<"$REQUIRED_WORKFLOWS_JSON")
          for wf in "${WORKFLOWS[@]}"; do
            RUN_ID=$(gh run list --workflow "$wf" --limit 50 \
              --json databaseId,headSha \
              --jq "map(select(.headSha==\"$SHA\"))[0].databaseId")
            [[ -z "$RUN_ID" || "$RUN_ID" == "null" ]] && { echo "No run for $wf (skipping)"; continue; }
            gh run download "$RUN_ID" --dir "inbox/$wf" || echo "No artifacts to download for $wf (run_id=$RUN_ID). Continuing."
          done

      - name: Stage downloaded artifacts into workspace
        shell: bash
        run: |
          set -euo pipefail
          shopt -s nullglob

          # 1) Merge all criterion trees into ./target/criterion so the collector finds them
          mkdir -p target/criterion
          while IFS= read -r -d '' critdir; do
            rsync -a "$critdir"/ target/criterion/
          done < <(find inbox -type d -path '*/target/criterion' -print0)

          # 2) Restore non-Rust metrics into workspace, preserving relative paths
          while IFS= read -r -d '' outdir; do
            rsync -a "$outdir"/ ./
          done < <(find inbox -type d -name 'benchmark-outputs-*' -print0)

          # 3) Restore Rust metrics into workspace, preserving relative paths
          while IFS= read -r -d '' mdir; do
            rsync -a "$mdir"/ ./
          done < <(find inbox -type d -name 'metrics-*' -print0)

      - name: Install Rust toolchain (stable)
        uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
          override: true
          profile: minimal

      - name: Build utils
        run: cargo build --release -p utils

      - name: Collect benchmarks
        run: |
          cd utils
          cargo run --release --bin collect_benchmarks

      - name: Upload collected reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: "collected-benchmarks"
          path: ./collected_benchmarks.json
          retention-days: 30
